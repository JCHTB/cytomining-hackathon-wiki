{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import load\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import keras\n",
    "import h5py\n",
    "\n",
    "from keras.datasets import cifar10\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.regularizers import WeightRegularizer, ActivityRegularizer, l2, activity_l2\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D, AveragePooling2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.optimizers import SGD\n",
    "from keras.utils import np_utils, generic_utils\n",
    "\n",
    "import theano\n",
    "theano.config.compute_test_value = 'off'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's load up the metadata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "meta_df = pd.DataFrame.from_csv('/home/ubuntu/metaframe.csv', index_col=False)\n",
    "meta_df['concentration'] = meta_df.concentration.apply(lambda x: '%0.3f' % x)\n",
    "meta_df['replicate'] = meta_df.replicate.apply(lambda x: str(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to define a dictionary from our model targets (the compounds) to integers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "target_mapper = dict(zip(meta_df['compound'].unique(),\n",
    "                         np.arange(meta_df['compound'].nunique())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we define a callback necessary for validating on a generator while also training on a generator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.callbacks import Callback\n",
    "\n",
    "class FineHistory(Callback):\n",
    "    def __init__(self, model, val_generator, n_samples=(2 ** 15)):\n",
    "        self.batch_loss = []\n",
    "        self.batch_size = []\n",
    "        self.epoch_loss = []\n",
    "        self.val_loss = []\n",
    "        self.val_acc = []\n",
    "        self.val_roc = []\n",
    "        self.model = model\n",
    "        self.val_generator = val_generator\n",
    "        self.n_samples = n_samples\n",
    "    \n",
    "    def on_epoch_begin(self, epoch, logs={}):\n",
    "        self.batch_loss.append([])\n",
    "        self.batch_size.append([])\n",
    "        \n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        losses = np.array(self.batch_loss[-1])\n",
    "        sizes = np.array(self.batch_size[-1])\n",
    "        self.epoch_loss.append(np.dot(losses, sizes) / np.sum(sizes))\n",
    "        self.batch_loss[-1] = losses\n",
    "        self.batch_size[-1] = sizes\n",
    "        val_loss, val_acc = self.model.evaluate_generator(self.val_generator, self.n_samples, verbose=0, show_accuracy=True)\n",
    "        self.val_loss.append(val_loss)\n",
    "        self.val_acc.append(val_acc)\n",
    "        logs['val_loss'] = self.val_loss[-1]\n",
    "        logs['val_acc'] = self.val_acc[-1]\n",
    "        \n",
    "    def on_batch_end(self, batch, logs={}):\n",
    "        self.batch_loss[-1].append(logs.get('loss'))\n",
    "        self.batch_size[-1].append(logs.get('size'))\n",
    "        \n",
    "def plot_cb(callback, y_range=None):    \n",
    "    p_loss = bop.figure(y_range=y_range)\n",
    "    p_loss.line(np.arange(0, len(callback.epoch_loss)),\n",
    "                callback.epoch_loss,\n",
    "                legend='Train Loss',\n",
    "                color='Blue')\n",
    "    p_loss.line(np.arange(0, len(callback.val_loss)),\n",
    "                callback.val_loss,\n",
    "                legend='Validation Loss',\n",
    "                color='Green')\n",
    "    \n",
    "    bop.show(p_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we define a simple keras model that is 3 layers deep. We have 2 convolutional layers (along with activations, pooling, and dropout). We also have a fully-connected layer as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.regularizers import WeightRegularizer\n",
    "\n",
    "def create_model(nb_classes, img_rows, img_cols, img_channels):\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(AveragePooling2D(pool_size=(3, 3), input_shape=(img_channels, img_rows, img_cols)))\n",
    "    model.add(Convolution2D(32, 3, 3, border_mode='same'))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(4, 4)))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(Convolution2D(64, 3, 3, border_mode='same'))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(4, 4)))\n",
    "    model.add(Dropout(0.25))\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(256))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    \n",
    "    model.add(Dense(nb_classes))\n",
    "    model.add(Activation('softmax'))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nb_classes = len(target_mapper)\n",
    "img_rows, img_cols = 192, 192\n",
    "img_channels = 3\n",
    "\n",
    "model = create_model(nb_classes, img_rows, img_cols, img_channels)\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's define our data generators using the `load` module (feel free to modify this). For each record of the passed metadata frame (whose rows are `compound`, `concentration`, `replicate`, and `moa`), a single randomly cropped image of the specified size will be returned in a minibatch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ds = h5py.File('/home/ubuntu/morphological_profiling_dl.h5', 'r')\n",
    "\n",
    "train_generator = load.minibatch_generator(ds, meta_df.query(\"replicate in ('1', '2')\"), target_mapper, size=192)\n",
    "validation_generator = load.minibatch_generator(ds, meta_df.query(\"replicate == '3'\"), target_mapper, size=192)\n",
    "\n",
    "cb = FineHistory(model, validation_generator, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "10098/10000 [==============================] - 229s - loss: 3.3900 - acc: 0.1065 - val_loss: 3.1685 - val_acc: 0.1350\n",
      "Epoch 2/5\n",
      "10098/10000 [==============================] - 258s - loss: 2.9705 - acc: 0.1719 - val_loss: 2.7980 - val_acc: 0.2114\n",
      "Epoch 3/5\n",
      "10098/10000 [==============================] - 281s - loss: 2.6244 - acc: 0.2237 - val_loss: 2.5545 - val_acc: 0.2345\n",
      "Epoch 4/5\n",
      "10098/10000 [==============================] - 287s - loss: 2.4201 - acc: 0.2628 - val_loss: 2.3733 - val_acc: 0.2664\n",
      "Epoch 5/5\n",
      "10098/10000 [==============================] - 292s - loss: 2.2602 - acc: 0.2914 - val_loss: 2.2643 - val_acc: 0.2880\n"
     ]
    }
   ],
   "source": [
    "nb_epoch = 25\n",
    "history = model.fit_generator(train_generator, callbacks=[cb],\n",
    "                              samples_per_epoch=5000,\n",
    "                              nb_epoch=nb_epoch, show_accuracy=True,\n",
    "                              nb_worker=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cool, we now have a trained model. Let's define a second model that will return the activations at the second to last layer. This can be considered a profile."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_base_network(layers):\n",
    "    seq = Sequential()\n",
    "    seq.add(AveragePooling2D(pool_size=(3, 3), input_shape=(3, 192, 192)))\n",
    "\n",
    "    seq.add(Convolution2D(32, 3, 3, border_mode='same', weights=layers[1].get_weights()))\n",
    "    seq.add(Activation('relu'))\n",
    "    seq.add(MaxPooling2D(pool_size=(4, 4)))\n",
    "    seq.add(Dropout(0.25))\n",
    "    \n",
    "    seq.add(Convolution2D(64, 3, 3, border_mode='same', weights=layers[5].get_weights()))\n",
    "    seq.add(Activation('relu'))\n",
    "    seq.add(MaxPooling2D(pool_size=(4, 4)))\n",
    "    seq.add(Dropout(0.25))\n",
    "    \n",
    "    seq.add(Flatten())\n",
    "    seq.add(Dense(256, weights=layers[10].get_weights()))\n",
    "    \n",
    "    return seq\n",
    "\n",
    "def get_activation_function(model):\n",
    "    layers = model.layers\n",
    "    seq = create_base_network(layers)\n",
    "    get_activations = theano.function([seq.layers[0].input], seq.layers[-1].get_output(train=False), allow_input_downcast=True)\n",
    "    return get_activations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also define some functions for calculating the distances between a bunch of vectors in a pandas dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import cdist\n",
    "\n",
    "def df_cdist(df1, df2, *args, **kwargs):\n",
    "    \"\"\"\n",
    "    Returns the matrix of pair-wise distances between the rows of df1 and\n",
    "    the rows of df2. Also works with Series.\n",
    "    We use scipy.spatial.distance.cdist (see online docs\n",
    "    http://docs.scipy.org/doc/scipy/reference/generated/\n",
    "    scipy.spatial.distance.cdist.html#scipy.spatial.distance.cdist)\n",
    "        \n",
    "    Parameters\n",
    "    ----------\n",
    "    df1 : pandas DataFrame\n",
    "        First dataframe.\n",
    "                                       \n",
    "    df2 : pandas DataFrame       \n",
    "        Second dataframe.\n",
    "    \n",
    "    args : arguments\n",
    "        Additional positional arguments.\n",
    "    \n",
    "    kwargs : arguments\n",
    "        Additional key-value arguments.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    distFrame : pandas DataFrame\n",
    "        DataFrame with N rows (where N = `len(df1)`) and M columns\n",
    "        (where M = `len(df2)`). The i,j^th entry is the distance\n",
    "        between row `i` of `df1` and row `j` of `df2`.\n",
    "    \"\"\"\n",
    "    # Handle Series\n",
    "    if isinstance(df1, pd.Series) and isinstance(df2, pd.Series):\n",
    "        distFrame = df_cdist(pd.DataFrame(df1).T, pd.DataFrame(df2).T,\n",
    "                             *args, **kwargs).iloc[0].iloc[0]\n",
    "    elif isinstance(df1, pd.Series):\n",
    "        distFrame = df_cdist(pd.DataFrame(df1).T, df2, *args, **kwargs).iloc[0]\n",
    "    elif isinstance(df2, pd.Series):\n",
    "        distFrame = df_cdist(df1, pd.DataFrame(df2).T, *args, **kwargs).icol(0)\n",
    "    else:\n",
    "        distFrame = pd.DataFrame(cdist(df1.values, df2.values,\n",
    "                                       *args, **kwargs),\n",
    "                                 index=df1.index, columns=df2.index)\n",
    "    return distFrame\n",
    "\n",
    "\n",
    "def df_cangle(df1, df2):\n",
    "    # clip because of numerical inaccuracy\n",
    "    costh = (1-df_cdist(df1, df2, metric='cosine')).clip(-1, 1)\n",
    "    return np.rad2deg(np.arccos(costh))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "activation_function = get_activation_function(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's load up some data..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Xs = []\n",
    "ys = []\n",
    "for _ in range(20):\n",
    "    X, y = train_generator.next()\n",
    "    Xs.append(X)\n",
    "    ys.append(y)\n",
    "    \n",
    "X = np.concatenate(Xs)\n",
    "Y = np.concatenate(ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "inv_target_mapper = {v: k for k, v in target_mapper.iteritems()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... and calculate the angles between the profiles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "latent_reps = pd.DataFrame(activation_function(X))\n",
    "latent_reps['drug'] = map(lambda x: inv_target_mapper[x], np.argmax(Y, axis=1))\n",
    "\n",
    "angles = df_cangle(latent_reps.groupby(['moa', 'drug']).mean(),\n",
    "                   latent_reps.groupby(['moa', 'drug']).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "angles"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
